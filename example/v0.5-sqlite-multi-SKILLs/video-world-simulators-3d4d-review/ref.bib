% ref.bib — Verified seed citations (arXiv-first via arxiv_registry.py)
%
% NOTE: Add entries only after verification.
% For arXiv papers, prefer:
%   python3 .codex/skills/arxiv-paper-writer/scripts/arxiv_registry.py \
%     --project-dir <paper_dir> export-bibtex <arxiv_id> --out-bib <paper_dir>/ref.bib

% ---------------------------------------------------------------------
% Frontier / product systems (official sources; web-verified)
% ---------------------------------------------------------------------

@misc{openai2024worldsimulators,
      title={Video generation models as world simulators},
      author={OpenAI},
      year={2024},
      howpublished={\url{https://openai.com/index/video-generation-models-as-world-simulators/}},
      note={Accessed: 2025-12-29},
}

@misc{openai2024sorasystemcard,
      title={Sora system card},
      author={OpenAI},
      year={2024},
      month=dec,
      day={9},
      howpublished={\url{https://openai.com/index/sora-system-card/}},
      note={Accessed: 2025-12-29},
}

@misc{openai2025sora2,
      title={Sora 2 is here},
      author={OpenAI},
      year={2025},
      month=sep,
      day={30},
      howpublished={\url{https://openai.com/index/sora-2-is-here/}},
      note={Accessed: 2025-12-29},
}

@misc{googlecloud2025veomodelapi,
      title={Veo on Vertex AI video generation API},
      author={{Google Cloud}},
      year={2025},
      howpublished={\url{https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo-video-generation}},
      note={Accessed: 2025-12-29},
}

@misc{googlecloud2025veo3,
      title={Veo 3 (Vertex AI model documentation)},
      author={{Google Cloud}},
      year={2025},
      howpublished={\url{https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/veo/3-0-generate}},
      note={Accessed: 2025-12-29},
}

@misc{googlecloud2025veo2,
      title={Veo 2 (Vertex AI model documentation)},
      author={{Google Cloud}},
      year={2025},
      howpublished={\url{https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/veo/2-0-generate}},
      note={Accessed: 2025-12-29},
}

@misc{runway2025gen45,
      title={Creating with Gen-4.5},
      author={{Runway}},
      year={2025},
      howpublished={\url{https://help.runwayml.com/hc/en-us/articles/46974685288467-Creating-with-Gen-4-5}},
      note={Accessed: 2025-12-29},
}

@misc{luma2025ray3,
      title={Ray3},
      author={{Luma AI}},
      year={2025},
      howpublished={\url{https://lumalabs.ai/press/ray3}},
      note={Accessed: 2025-12-29},
}

@misc{pika2024raises80m,
      title={Pika raises \$80M, so anyone can make video on command},
      author={{Pika}},
      year={2024},
      month=jun,
      day={5},
      howpublished={\url{https://pika.art/blog}},
      note={Accessed: 2025-12-29},
}

@misc{c2pa2025spec,
      title={C2PA Specification},
      author={{Coalition for Content Provenance and Authenticity (C2PA)}},
      year={2025},
      howpublished={\url{https://c2pa.org/specifications/}},
      note={Accessed: 2025-12-29},
}

@misc{googledeepmind2025synthid,
      title={SynthID},
      author={{Google DeepMind}},
      year={2025},
      howpublished={\url{https://deepmind.google/technologies/synthid/}},
      note={Accessed: 2025-12-29},
}

@misc{ho2022video,
      title={Video Diffusion Models}, 
      author={Jonathan Ho and Tim Salimans and Alexey Gritsenko and William Chan and Mohammad Norouzi and David J. Fleet},
      year={2022},
      eprint={2204.03458},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.03458}, 
}

@misc{ho2022imagen,
      title={Imagen Video: High Definition Video Generation with Diffusion Models}, 
      author={Jonathan Ho and William Chan and Chitwan Saharia and Jay Whang and Ruiqi Gao and Alexey Gritsenko and Diederik P. Kingma and Ben Poole and Mohammad Norouzi and David J. Fleet and Tim Salimans},
      year={2022},
      eprint={2210.02303},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.02303}, 
}

@misc{singer2022make,
      title={Make-A-Video: Text-to-Video Generation without Text-Video Data}, 
      author={Uriel Singer and Adam Polyak and Thomas Hayes and Xi Yin and Jie An and Songyang Zhang and Qiyuan Hu and Harry Yang and Oron Ashual and Oran Gafni and Devi Parikh and Sonal Gupta and Yaniv Taigman},
      year={2022},
      eprint={2209.14792},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2209.14792}, 
}

@misc{villegas2022phenaki,
      title={Phenaki: Variable Length Video Generation From Open Domain Textual Description}, 
      author={Ruben Villegas and Mohammad Babaeizadeh and Pieter-Jan Kindermans and Hernan Moraldo and Han Zhang and Mohammad Taghi Saffar and Santiago Castro and Julius Kunze and Dumitru Erhan},
      year={2022},
      eprint={2210.02399},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.02399}, 
}

@misc{blattmann2023stable,
      title={Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets}, 
      author={Andreas Blattmann and Tim Dockhorn and Sumith Kulal and Daniel Mendelevitch and Maciej Kilian and Dominik Lorenz and Yam Levi and Zion English and Vikram Voleti and Adam Letts and Varun Jampani and Robin Rombach},
      year={2023},
      eprint={2311.15127},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.15127}, 
}

@misc{bartal2024lumiere,
      title={Lumiere: A Space-Time Diffusion Model for Video Generation}, 
      author={Omer Bar-Tal and Hila Chefer and Omer Tov and Charles Herrmann and Roni Paiss and Shiran Zada and Ariel Ephrat and Junhwa Hur and Guanghui Liu and Amit Raj and Yuanzhen Li and Michael Rubinstein and Tomer Michaeli and Oliver Wang and Deqing Sun and Tali Dekel and Inbar Mosseri},
      year={2024},
      eprint={2401.12945},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2401.12945}, 
}

@misc{kondratyuk2023videopoet,
      title={VideoPoet: A Large Language Model for Zero-Shot Video Generation}, 
      author={Dan Kondratyuk and Lijun Yu and Xiuye Gu and José Lezama and Jonathan Huang and Grant Schindler and Rachel Hornung and Vighnesh Birodkar and Jimmy Yan and Ming-Chang Chiu and Krishna Somandepalli and Hassan Akbari and Yair Alon and Yong Cheng and Josh Dillon and Agrim Gupta and Meera Hahn and Anja Hauth and David Hendon and Alonso Martinez and David Minnen and Mikhail Sirotenko and Kihyuk Sohn and Xuan Yang and Hartwig Adam and Ming-Hsuan Yang and Irfan Essa and Huisheng Wang and David A. Ross and Bryan Seybold and Lu Jiang},
      year={2024},
      eprint={2312.14125},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.14125}, 
}

@misc{polyak2024movie,
      title={Movie Gen: A Cast of Media Foundation Models}, 
      author={Adam Polyak and Amit Zohar and Andrew Brown and Andros Tjandra and Animesh Sinha and Ann Lee and Apoorv Vyas and Bowen Shi and Chih-Yao Ma and Ching-Yao Chuang and David Yan and Dhruv Choudhary and Dingkang Wang and Geet Sethi and Guan Pang and Haoyu Ma and Ishan Misra and Ji Hou and Jialiang Wang and Kiran Jagadeesh and Kunpeng Li and Luxin Zhang and Mannat Singh and Mary Williamson and Matt Le and Matthew Yu and Mitesh Kumar Singh and Peizhao Zhang and Peter Vajda and Quentin Duval and Rohit Girdhar and Roshan Sumbaly and Sai Saketh Rambhatla and Sam Tsai and Samaneh Azadi and Samyak Datta and Sanyuan Chen and Sean Bell and Sharadh Ramaswamy and Shelly Sheynin and Siddharth Bhattacharya and Simran Motwani and Tao Xu and Tianhe Li and Tingbo Hou and Wei-Ning Hsu and Xi Yin and Xiaoliang Dai and Yaniv Taigman and Yaqiao Luo and Yen-Cheng Liu and Yi-Chiao Wu and Yue Zhao and Yuval Kirstain and Zecheng He and Zijian He and Albert Pumarola and Ali Thabet and Artsiom Sanakoyeu and Arun Mallya and Baishan Guo and Boris Araya and Breena Kerr and Carleigh Wood and Ce Liu and Cen Peng and Dimitry Vengertsev and Edgar Schonfeld and Elliot Blanchard and Felix Juefei-Xu and Fraylie Nord and Jeff Liang and John Hoffman and Jonas Kohler and Kaolin Fire and Karthik Sivakumar and Lawrence Chen and Licheng Yu and Luya Gao and Markos Georgopoulos and Rashel Moritz and Sara K. Sampson and Shikai Li and Simone Parmeggiani and Steve Fine and Tara Fowler and Vladan Petrovic and Yuming Du},
      year={2025},
      eprint={2410.13720},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.13720}, 
}

@misc{bruce2024genie,
      title={Genie: Generative Interactive Environments}, 
      author={Jake Bruce and Michael Dennis and Ashley Edwards and Jack Parker-Holder and Yuge Shi and Edward Hughes and Matthew Lai and Aditi Mavalankar and Richie Steigerwald and Chris Apps and Yusuf Aytar and Sarah Bechtle and Feryal Behbahani and Stephanie Chan and Nicolas Heess and Lucy Gonzalez and Simon Osindero and Sherjil Ozair and Scott Reed and Jingwei Zhang and Konrad Zolna and Jeff Clune and Nando de Freitas and Satinder Singh and Tim Rocktäschel},
      year={2024},
      eprint={2402.15391},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.15391}, 
}

@misc{savov2025exploration,
      title={Exploration-Driven Generative Interactive Environments}, 
      author={Nedko Savov and Naser Kazemi and Mohammad Mahdi and Danda Pani Paudel and Xi Wang and Luc Van Gool},
      year={2025},
      eprint={2504.02515},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.02515}, 
}

@misc{guo2023animatediff,
      title={AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning}, 
      author={Yuwei Guo and Ceyuan Yang and Anyi Rao and Zhengyang Liang and Yaohui Wang and Yu Qiao and Maneesh Agrawala and Dahua Lin and Bo Dai},
      year={2024},
      eprint={2307.04725},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.04725}, 
}

@misc{wang2023motionctrl,
      title={MotionCtrl: A Unified and Flexible Motion Controller for Video Generation}, 
      author={Zhouxia Wang and Ziyang Yuan and Xintao Wang and Tianshui Chen and Menghan Xia and Ping Luo and Ying Shan},
      year={2024},
      eprint={2312.03641},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.03641}, 
}

@misc{qiu2024freetraj,
      title={FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models}, 
      author={Haonan Qiu and Zhaoxi Chen and Zhouxia Wang and Yingqing He and Menghan Xia and Ziwei Liu},
      year={2024},
      eprint={2406.16863},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.16863}, 
}

@misc{zhang2025think,
      title={Think Before You Diffuse: Infusing Physical Rules into Video Diffusion}, 
      author={Ke Zhang and Cihan Xiao and Jiacong Xu and Yiqun Mei and Vishal M. Patel},
      year={2025},
      eprint={2505.21653},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.21653}, 
}

@misc{zhang2024physdreamer,
      title={PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation}, 
      author={Tianyuan Zhang and Hong-Xing Yu and Rundi Wu and Brandon Y. Feng and Changxi Zheng and Noah Snavely and Jiajun Wu and William T. Freeman},
      year={2024},
      eprint={2404.13026},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.13026}, 
}

@misc{mildenhall2020nerf,
      title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis}, 
      author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
      year={2020},
      eprint={2003.08934},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2003.08934}, 
}

@misc{kerbl20233d,
      title={3D Gaussian Splatting for Real-Time Radiance Field Rendering}, 
      author={Bernhard Kerbl and Georgios Kopanas and Thomas Leimkühler and George Drettakis},
      year={2023},
      eprint={2308.04079},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2308.04079}, 
}

@misc{wu20234d,
      title={4D Gaussian Splatting for Real-Time Dynamic Scene Rendering}, 
      author={Guanjun Wu and Taoran Yi and Jiemin Fang and Lingxi Xie and Xiaopeng Zhang and Wei Wei and Wenyu Liu and Qi Tian and Xinggang Wang},
      year={2024},
      eprint={2310.08528},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2310.08528}, 
}

@misc{ling2023align,
      title={Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models}, 
      author={Huan Ling and Seung Wook Kim and Antonio Torralba and Sanja Fidler and Karsten Kreis},
      year={2024},
      eprint={2312.13763},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.13763}, 
}

@misc{miao2024pla4d,
      title={PLA4D: Pixel-Level Alignments for Text-to-4D Gaussian Splatting}, 
      author={Qiaowei Miao and JinSheng Quan and Kehan Li and Yawei Luo},
      year={2024},
      eprint={2405.19957},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.19957}, 
}

@misc{unterthiner2018towards,
      title={Towards Accurate Generative Models of Video: A New Metric and Challenges}, 
      author={Thomas Unterthiner and Sjoerd van Steenkiste and Karol Kurach and Raphael Marinier and Marcin Michalski and Sylvain Gelly},
      year={2019},
      eprint={1812.01717},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1812.01717}, 
}

@misc{huang2023vbench,
      title={VBench: Comprehensive Benchmark Suite for Video Generative Models}, 
      author={Ziqi Huang and Yinan He and Jiashuo Yu and Fan Zhang and Chenyang Si and Yuming Jiang and Yuanhan Zhang and Tianxing Wu and Qingyang Jin and Nattapol Chanpaisit and Yaohui Wang and Xinyuan Chen and Limin Wang and Dahua Lin and Yu Qiao and Ziwei Liu},
      year={2023},
      eprint={2311.17982},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.17982}, 
}

@misc{sun2024t2v,
      title={T2V-CompBench: A Comprehensive Benchmark for Compositional Text-to-video Generation}, 
      author={Kaiyue Sun and Kaiyi Huang and Xian Liu and Yue Wu and Zihan Xu and Zhenguo Li and Xihui Liu},
      year={2025},
      eprint={2407.14505},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.14505}, 
}
@misc{ho2020denoising,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.11239}, 
}

@misc{rombach2021high,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}

@misc{song2020score,
      title={Score-Based Generative Modeling through Stochastic Differential Equations}, 
      author={Yang Song and Jascha Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
      year={2021},
      eprint={2011.13456},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2011.13456}, 
}

@misc{peebles2022scalable,
      title={Scalable Diffusion Models with Transformers}, 
      author={William Peebles and Saining Xie},
      year={2023},
      eprint={2212.09748},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.09748}, 
}

@misc{liu2022flow,
      title={Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow}, 
      author={Xingchao Liu and Chengyue Gong and Qiang Liu},
      year={2022},
      eprint={2209.03003},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.03003}, 
}

@misc{lipman2022flow,
      title={Flow Matching for Generative Modeling}, 
      author={Yaron Lipman and Ricky T. Q. Chen and Heli Ben-Hamu and Maximilian Nickel and Matt Le},
      year={2023},
      eprint={2210.02747},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.02747}, 
}

@misc{chen2024motion,
      title={Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation}, 
      author={Changgu Chen and Junwei Shu and Gaoqi He and Changbo Wang and Yang Li},
      year={2025},
      eprint={2401.10150},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2401.10150}, 
}

@misc{wu2022tune,
      title={Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation}, 
      author={Jay Zhangjie Wu and Yixiao Ge and Xintao Wang and Weixian Lei and Yuchao Gu and Yufei Shi and Wynne Hsu and Ying Shan and Xiaohu Qie and Mike Zheng Shou},
      year={2023},
      eprint={2212.11565},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.11565}, 
}

@misc{liu2023video,
      title={Video-P2P: Video Editing with Cross-attention Control}, 
      author={Shaoteng Liu and Yuechen Zhang and Wenbo Li and Zhe Lin and Jiaya Jia},
      year={2023},
      eprint={2303.04761},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.04761}, 
}

@misc{li2024enhancing,
      title={Enhancing Long Video Generation Consistency without Tuning}, 
      author={Xingyao Li and Fengzhuo Zhang and Jiachun Pan and Yunlong Hou and Vincent Y. F. Tan and Zhuoran Yang},
      year={2025},
      eprint={2412.17254},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.17254}, 
}

@misc{zhang2024recapture,
      title={ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning}, 
      author={David Junhao Zhang and Roni Paiss and Shiran Zada and Nikhil Karnad and David E. Jacobs and Yael Pritch and Inbar Mosseri and Mike Zheng Shou and Neal Wadhwa and Nataniel Ruiz},
      year={2024},
      eprint={2411.05003},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.05003}, 
}

@misc{gu2025diffusion,
      title={Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control}, 
      author={Zekai Gu and Rui Yan and Jiahao Lu and Peng Li and Zhiyang Dou and Chenyang Si and Zhen Dong and Qifeng Liu and Cheng Lin and Ziwei Liu and Wenping Wang and Yuan Liu},
      year={2025},
      eprint={2501.03847},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.03847}, 
}

@misc{jeong2025reangle,
      title={Reangle-A-Video: 4D Video Generation as Video-to-Video Translation}, 
      author={Hyeonho Jeong and Suhyeon Lee and Jong Chul Ye},
      year={2025},
      eprint={2503.09151},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.09151}, 
}

@misc{wang2025bullettime,
      title={BulletTime: Decoupled Control of Time and Camera Pose for Video Generation}, 
      author={Yiming Wang and Qihang Zhang and Shengqu Cai and Tong Wu and Jan Ackermann and Zhengfei Kuang and Yang Zheng and Frano Rajič and Siyu Tang and Gordon Wetzstein},
      year={2025},
      eprint={2512.05076},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.05076}, 
}

@misc{romero2025learning,
      title={Learning to Generate Rigid Body Interactions with Video Diffusion Models}, 
      author={David Romero and Ariana Bermudez and Hao Li and Fabio Pizzati and Ivan Laptev},
      year={2025},
      eprint={2510.02284},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.02284}, 
}

@misc{yang2025geniedrive,
      title={GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation}, 
      author={Zhenya Yang and Zhe Liu and Yuxiang Lu and Liping Hou and Chenxuan Miao and Siyi Peng and Bailan Feng and Xiang Bai and Hengshuang Zhao},
      year={2025},
      eprint={2512.12751},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.12751}, 
}

@misc{poole2022dreamfusion,
      title={DreamFusion: Text-to-3D using 2D Diffusion}, 
      author={Ben Poole and Ajay Jain and Jonathan T. Barron and Ben Mildenhall},
      year={2022},
      eprint={2209.14988},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2209.14988}, 
}

@misc{tang2023dreamgaussian,
      title={DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation}, 
      author={Jiaxiang Tang and Jiawei Ren and Hang Zhou and Ziwei Liu and Gang Zeng},
      year={2024},
      eprint={2309.16653},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.16653}, 
}

@misc{ren2023dreamgaussian4d,
      title={DreamGaussian4D: Generative 4D Gaussian Splatting}, 
      author={Jiawei Ren and Liang Pan and Jiaxiang Tang and Chi Zhang and Ang Cao and Gang Zeng and Ziwei Liu},
      year={2024},
      eprint={2312.17142},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.17142}, 
}

@misc{deng2025stp4d,
      title={STP4D: Spatio-Temporal-Prompt Consistent Modeling for Text-to-4D Gaussian Splatting}, 
      author={Yunze Deng and Haijun Xiong and Bin Feng and Xinggang Wang and Wenyu Liu},
      year={2025},
      eprint={2504.18318},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.18318}, 
}

@misc{xu20254dgt,
      title={4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos}, 
      author={Zhen Xu and Zhengqin Li and Zhao Dong and Xiaowei Zhou and Richard Newcombe and Zhaoyang Lv},
      year={2025},
      eprint={2506.08015},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.08015}, 
}

@misc{pumarola2020d,
      title={D-NeRF: Neural Radiance Fields for Dynamic Scenes}, 
      author={Albert Pumarola and Enric Corona and Gerard Pons-Moll and Francesc Moreno-Noguer},
      year={2020},
      eprint={2011.13961},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2011.13961}, 
}

@misc{mou2025gradeo,
      title={GRADEO: Towards Human-Like Evaluation for Text-to-Video Generation via Multi-Step Reasoning}, 
      author={Zhun Mou and Bin Xia and Zhengchao Huang and Wenming Yang and Jiaya Jia},
      year={2025},
      eprint={2503.02341},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.02341}, 
}

@misc{hua2025vabench,
      title={VABench: A Comprehensive Benchmark for Audio-Video Generation}, 
      author={Daili Hua and Xizhi Wang and Bohan Zeng and Xinyi Huang and Hao Liang and Junbo Niu and Xinlong Chen and Quanqing Xu and Wentao Zhang},
      year={2025},
      eprint={2512.09299},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.09299}, 
}

@misc{chen2025tivibench,
      title={TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models}, 
      author={Harold Haodong Chen and Disen Lan and Wen-Jie Shu and Qingyang Liu and Zihan Wang and Sirui Chen and Wenkai Cheng and Kanghao Chen and Hongfei Zhang and Zixin Zhang and Rongjin Guo and Yu Cheng and Ying-Cong Chen},
      year={2025},
      eprint={2511.13704},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2511.13704}, 
}

@misc{cao2025t2av,
      title={T2AV-Compass: Towards Unified Evaluation for Text-to-Audio-Video Generation}, 
      author={Zhe Cao and Tao Wang and Jiaming Wang and Yanghai Wang and Yuanxing Zhang and Jialu Chen and Miao Deng and Jiahao Wang and Yubin Guo and Chenxi Liao and Yize Zhang and Zhaoxiang Zhang and Jiaheng Liu},
      year={2025},
      eprint={2512.21094},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.21094}, 
}

@misc{zhang2023adding,
      title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
      author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
      year={2023},
      eprint={2302.05543},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2302.05543}, 
}

@misc{fares2025spdmark,
      title={SPDMark: Selective Parameter Displacement for Robust Video Watermarking}, 
      author={Samar Fares and Nurbek Tastan and Karthik Nandakumar},
      year={2025},
      eprint={2512.12090},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.12090}, 
}

@misc{wang2025robustsora,
      title={RobustSora: De-Watermarked Benchmark for Robust AI-Generated Video Detection}, 
      author={Zhuo Wang and Xiliang Liu and Ligang Sun},
      year={2025},
      eprint={2512.10248},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.10248}, 
}

@misc{wang2025video,
      title={Video Reality Test: Can AI-Generated ASMR Videos fool VLMs and Humans?}, 
      author={Jiaqi Wang and Weijia Wu and Yi Zhan and Rui Zhao and Ming Hu and James Cheng and Wei Liu and Philip Torr and Kevin Qinghong Lin},
      year={2025},
      eprint={2512.13281},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.13281}, 
}

@misc{zhao2025rdsplat,
      title={RDSplat: Robust Watermarking Against Diffusion Editing for 3D Gaussian Splatting}, 
      author={Longjie Zhao and Ziming Hong and Zhenyang Ren and Runnan Chen and Mingming Gong and Tongliang Liu},
      year={2025},
      eprint={2512.06774},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.06774}, 
}

@misc{jeong2025waterflow,
      title={WaTeRFlow: Watermark Temporal Robustness via Flow Consistency}, 
      author={Utae Jeong and Sumin In and Hyunju Ryu and Jaewan Choi and Feng Yang and Jongheon Jeong and Seungryong Kim and Sangpil Kim},
      year={2025},
      eprint={2512.19048},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.19048}, 
}
@misc{zhang2025vhoi,
      title={VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification}, 
      author={Wanyue Zhang and Lin Geng Foo and Thabo Beeler and Rishabh Dabral and Christian Theobalt},
      year={2025},
      eprint={2512.09646},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.09646}, 
}

@misc{ni2025from,
      title={From Generated Human Videos to Physically Plausible Robot Trajectories}, 
      author={James Ni and Zekai Wang and Wei Lin and Amir Bar and Yann LeCun and Trevor Darrell and Jitendra Malik and Roei Herzig},
      year={2025},
      eprint={2512.05094},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2512.05094}, 
}

@misc{ci2025h2r,
      title={H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos}, 
      author={Hai Ci and Xiaokang Liu and Pei Yang and Yiren Song and Mike Zheng Shou},
      year={2025},
      eprint={2512.09406},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2512.09406}, 
}

@misc{yu2025lina,
      title={LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models}, 
      author={Shu Yu and Chaochao Lu},
      year={2025},
      eprint={2512.13290},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.13290}, 
}

@misc{asiimwe20254d,
      title={4D Gaussian Splatting as a Learned Dynamical System}, 
      author={Arnold Caleb Asiimwe and Carl Vondrick},
      year={2025},
      eprint={2512.19648},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.19648}, 
}

@misc{fan2025omniview,
      title={OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis}, 
      author={Xiang Fan and Sharath Girish and Vivek Ramanujan and Chaoyang Wang and Ashkan Mirzaei and Petr Sushko and Aliaksandr Siarohin and Sergey Tulyakov and Ranjay Krishna},
      year={2025},
      eprint={2512.10940},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.10940}, 
}

@misc{hassan2025factorized,
      title={Factorized Video Generation: Decoupling Scene Construction and Temporal Synthesis in Text-to-Video Diffusion Models}, 
      author={Mariam Hassan and Bastien Van Delft and Wuyang Li and Alexandre Alahi},
      year={2025},
      eprint={2512.16371},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.16371}, 
}

@misc{zhang2025endless,
      title={Endless World: Real-Time 3D-Aware Long Video Generation}, 
      author={Ke Zhang and Yiqun Mei and Jiacong Xu and Vishal M. Patel},
      year={2025},
      eprint={2512.12430},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.12430}, 
}

@misc{kong2025worldwarp,
      title={WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion}, 
      author={Hanyang Kong and Xingyi Yang and Xiaoxu Zheng and Xinchao Wang},
      year={2025},
      eprint={2512.19678},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.19678}, 
}

@misc{liu2025infinitystar,
      title={InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation}, 
      author={Jinlai Liu and Jian Han and Bin Yan and Hui Wu and Fengda Zhu and Xing Wang and Yi Jiang and Bingyue Peng and Zehuan Yuan},
      year={2025},
      eprint={2511.04675},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2511.04675}, 
}

@misc{zhu2025astra,
      title={Astra: General Interactive World Model with Autoregressive Denoising}, 
      author={Yixuan Zhu and Jiaqi Feng and Wenzhao Zheng and Yuan Gao and Xin Tao and Pengfei Wan and Jie Zhou and Jiwen Lu},
      year={2025},
      eprint={2512.08931},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.08931}, 
}

@misc{jain2025lights,
      title={Lights, Camera, Consistency: A Multistage Pipeline for Character-Stable AI Video Stories}, 
      author={Chayan Jain and Rishant Sharma and Archit Garg and Ishan Bhanuka and Pratik Narang and Dhruv Kumar},
      year={2025},
      eprint={2512.16954},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.16954}, 
}

@misc{fei2025structure,
      title={Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation}, 
      author={Yang Fei and George Stoica and Jingyuan Liu and Qifeng Chen and Ranjay Krishna and Xiaojuan Wang and Benlin Liu},
      year={2025},
      eprint={2512.11792},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.11792}, 
}

@misc{zhang2025region,
      title={Region-Constraint In-Context Generation for Instructional Video Editing}, 
      author={Zhongwei Zhang and Fuchen Long and Wei Li and Zhaofan Qiu and Wu Liu and Ting Yao and Tao Mei},
      year={2025},
      eprint={2512.17650},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.17650}, 
}

@misc{lee2025synctrack4d,
      title={SyncTrack4D: Cross-Video Motion Alignment and Video Synchronization for Multi-Video 4D Gaussian Splatting}, 
      author={Yonghan Lee and Tsung-Wei Huang and Shiv Gehlot and Jaehoon Choi and Guan-Ming Su and Dinesh Manocha},
      year={2025},
      eprint={2512.04315},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.04315}, 
}

